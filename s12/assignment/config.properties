# TorchServe Configuration
# Model downloads from HuggingFace at runtime

inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082

# Enable environment variables config
enable_envvars_config=true

# Install Python dependencies from requirements.txt
install_py_dep_per_model=true

# Load all models in model_store on startup
load_models=all

# Max response size (650MB for large images)
max_response_size=655350000

# Model store location
model_store=/tmp/models

# Response timeout (10 minutes for model download + generation)
default_response_timeout=600

# Enable metrics
enable_metrics_api=true

# Disable token authorization for easier testing
disable_token_authorization=true
